{"title":"Why Simple Models Are Sometimes Better","markdown":{"yaml":{"title":"Why Simple Models Are Sometimes Better","subtitle":"What poverty targeting in public policy reveals about the limits of complex machine learning models","author":"Yanxin Liang","date":"2026-01-18","bibliography":"../../references.bib"},"headingText":"When Models Decide, Not Just Predict","containsRefs":false,"markdown":"\n\nMachine learning models are widely used in real-world decision-making. In banking, predictive models estimate the risk of loan default. In healthcare, models assess patient risk and help allocate medical resources. In data science, there is a common assumption that more complex models lead to better outcomes. Random forests, gradient boosting, and neural networks are often preferred because they can capture complex patterns and achieve higher predictive accuracy.\n\nHowever, this assumption begins to break down when models move from prediction to decision-making. In many real-world settings, especially in public policy, models do not simply forecast outcomes. They determine who receives resources, who is prioritized, and who is excluded. In these cases, accuracy alone is rarely the only objective, and sometimes it is not even the most important one.\n\nThis post focuses on one such setting: poverty targeting in social assistance programs. It shows why, despite advances in machine learning, simple and interpretable models continue to dominate in practice.\n\nIn a typical machine learning workflow, models are evaluated using metrics such as accuracy or AUC. These metrics assume that the goal is to predict an outcome as precisely as possible. \n\nWhen a government uses a model to decide eligibility for social assistance, the model’s output becomes a decision. Policymakers must be able to defend that decision. Citizens expect transparency. Legal systems may require that decisions be explainable and open to appeal.\n\nIn this setting, a model that performs well but cannot be explained is not just inconvenient, it can be unusable. Even a small improvement in accuracy may not justify the loss of transparency.  As a result, what counts as “good performance” changes.\n\n## Poverty Targeting: A High-Stakes Data Science Problem\nPoverty targeting refers to the process of identifying which households should receive social assistance when resources are limited. There is a fundamental question brought to the  governments and international organizations: who should receive support, and who should not?\n\nFrom a data science perspective, this looks like a standard classification or ranking problem. Given household data, we try to identify those most in need. But in practice, it is also a political and social problem. Errors are visible, personal, and contested. \nExcluding a poor household can have serious consequences for food security, education, or healthcare. Including a household that is perceived as “not poor enough” can trigger public criticism and undermine trust in the system.\n\nBecause of this, poverty targeting systems are expected to be fair, consistent, and stable over time. These expectations strongly influence which models can actually be used.\n\n## Why Simple Models Work Better in Poverty Targeting\nIn practice, poverty targeting systems around the world rely heavily on simple models. This is not because governments are unaware of newer techniques, but because simple models fit the problem better.\n\nFirst, decisions must be explainable and contestable. When a household is denied benefits, it should be possible to explain why in plain terms.  Simple models allow governments to point to the observable characteristics, such as household size, education level, and housing quality, and explain how these contributed to the final decision.Complex models often struggle to provide explanations that feel intuitive or convincing to non-technical audiences.\n\nSecond, governance and oversight matter. Social assistance programs must be audited and monitored. Simple models are easier to inspect, test, and debug. Their logic can be reviewed by policymakers. Complex models require specialized expertise to interpret, which raises barriers to oversight.\n\nThird, stability often matters more than marginal accuracy. Rules for social assistance cannot change frequently or it could create confusion and unfairness. Simple models tend to be more stable, while complex models can produce different outcomes after retraining, even when underlying conditions have not changed much.\n\n## The Proxy Means Test: A Simple Model That Works\nOne of the most common tools used in poverty targeting is the Proxy Means Test (PMT). A PMT estimates household welfare using observable characteristics such as assets, education, housing quality, and household composition. Each feature is assigned a weight, and the total score determines eligibility.\n\nStatistically, a PMT is a linear scorecard, it aggregates all scores, usually weighted, to provide a single overall rating.  It is similar to the models such as linear models or logistic regression models. Although the model is simple, it is based on real data showing how household characteristics relate to poverty\n\nThe strength of PMTs comes from their transparency. The scoring rule can be published, replicated, and explained. Households can verify their information, and governments can audit outcomes. These properties make PMTs practical at scale, even if they do not achieve the highest possible predictive accuracy.\n\n## Where Complex Models Fit, and Where They Don’t\nRecent studies have explored using machine learning to improve poverty targeting, often relying on alternative data sources such as mobile phone records or satellite imagery. These approaches are attractive because they can reduce data collection costs and scale quickly in settings where traditional household surveys are expensive or outdated. For example, @aiken2022 use mobile phone metadata to predict poverty and target emergency cash transfers in Togo, showing that machine learning can improve targeting when conventional data are unavailable.\n\nHowever, evidence also suggests that greater model complexity does not always lead to better outcomes. @aiken2025 compare traditional Proxy Means Tests with machine-learning-based targeting methods using mobile phone data. They find that when high-quality survey data are available, PMTs often perform as well as or better than more complex models, while machine learning mainly offers advantages in scalability and cost. This highlights that the choice of model depends on context rather than complexity alone.\nThis does not mean that machine learning has no role in poverty targeting. It means that the “better” model depends on what kind of failure matters most. If the main risk is limited coverage, a complex machine learning  model may help. If the main concern is whether decisions can be justified and trusted, simpler models are safer.\n\n## What Poverty Targeting Teaches Us About Model Choice\nThe case of poverty targeting illustrates a broader lesson for data science practice. Model selection should not be driven solely by benchmark performance. In high-stakes domains, interpretability, auditability, and trust are part of the objective function.\nWhen models allocate resources rather than predict outcomes, accuracy alone is not enough. The best model is not the one with the highest score on a validation set, but the one that works within real institutional constraints.\n\nWhen accuracy is not the objective function, complex models lose their advantage.\n\n## References","srcMarkdownNoYaml":"\n\nMachine learning models are widely used in real-world decision-making. In banking, predictive models estimate the risk of loan default. In healthcare, models assess patient risk and help allocate medical resources. In data science, there is a common assumption that more complex models lead to better outcomes. Random forests, gradient boosting, and neural networks are often preferred because they can capture complex patterns and achieve higher predictive accuracy.\n\nHowever, this assumption begins to break down when models move from prediction to decision-making. In many real-world settings, especially in public policy, models do not simply forecast outcomes. They determine who receives resources, who is prioritized, and who is excluded. In these cases, accuracy alone is rarely the only objective, and sometimes it is not even the most important one.\n\nThis post focuses on one such setting: poverty targeting in social assistance programs. It shows why, despite advances in machine learning, simple and interpretable models continue to dominate in practice.\n\n## When Models Decide, Not Just Predict\nIn a typical machine learning workflow, models are evaluated using metrics such as accuracy or AUC. These metrics assume that the goal is to predict an outcome as precisely as possible. \n\nWhen a government uses a model to decide eligibility for social assistance, the model’s output becomes a decision. Policymakers must be able to defend that decision. Citizens expect transparency. Legal systems may require that decisions be explainable and open to appeal.\n\nIn this setting, a model that performs well but cannot be explained is not just inconvenient, it can be unusable. Even a small improvement in accuracy may not justify the loss of transparency.  As a result, what counts as “good performance” changes.\n\n## Poverty Targeting: A High-Stakes Data Science Problem\nPoverty targeting refers to the process of identifying which households should receive social assistance when resources are limited. There is a fundamental question brought to the  governments and international organizations: who should receive support, and who should not?\n\nFrom a data science perspective, this looks like a standard classification or ranking problem. Given household data, we try to identify those most in need. But in practice, it is also a political and social problem. Errors are visible, personal, and contested. \nExcluding a poor household can have serious consequences for food security, education, or healthcare. Including a household that is perceived as “not poor enough” can trigger public criticism and undermine trust in the system.\n\nBecause of this, poverty targeting systems are expected to be fair, consistent, and stable over time. These expectations strongly influence which models can actually be used.\n\n## Why Simple Models Work Better in Poverty Targeting\nIn practice, poverty targeting systems around the world rely heavily on simple models. This is not because governments are unaware of newer techniques, but because simple models fit the problem better.\n\nFirst, decisions must be explainable and contestable. When a household is denied benefits, it should be possible to explain why in plain terms.  Simple models allow governments to point to the observable characteristics, such as household size, education level, and housing quality, and explain how these contributed to the final decision.Complex models often struggle to provide explanations that feel intuitive or convincing to non-technical audiences.\n\nSecond, governance and oversight matter. Social assistance programs must be audited and monitored. Simple models are easier to inspect, test, and debug. Their logic can be reviewed by policymakers. Complex models require specialized expertise to interpret, which raises barriers to oversight.\n\nThird, stability often matters more than marginal accuracy. Rules for social assistance cannot change frequently or it could create confusion and unfairness. Simple models tend to be more stable, while complex models can produce different outcomes after retraining, even when underlying conditions have not changed much.\n\n## The Proxy Means Test: A Simple Model That Works\nOne of the most common tools used in poverty targeting is the Proxy Means Test (PMT). A PMT estimates household welfare using observable characteristics such as assets, education, housing quality, and household composition. Each feature is assigned a weight, and the total score determines eligibility.\n\nStatistically, a PMT is a linear scorecard, it aggregates all scores, usually weighted, to provide a single overall rating.  It is similar to the models such as linear models or logistic regression models. Although the model is simple, it is based on real data showing how household characteristics relate to poverty\n\nThe strength of PMTs comes from their transparency. The scoring rule can be published, replicated, and explained. Households can verify their information, and governments can audit outcomes. These properties make PMTs practical at scale, even if they do not achieve the highest possible predictive accuracy.\n\n## Where Complex Models Fit, and Where They Don’t\nRecent studies have explored using machine learning to improve poverty targeting, often relying on alternative data sources such as mobile phone records or satellite imagery. These approaches are attractive because they can reduce data collection costs and scale quickly in settings where traditional household surveys are expensive or outdated. For example, @aiken2022 use mobile phone metadata to predict poverty and target emergency cash transfers in Togo, showing that machine learning can improve targeting when conventional data are unavailable.\n\nHowever, evidence also suggests that greater model complexity does not always lead to better outcomes. @aiken2025 compare traditional Proxy Means Tests with machine-learning-based targeting methods using mobile phone data. They find that when high-quality survey data are available, PMTs often perform as well as or better than more complex models, while machine learning mainly offers advantages in scalability and cost. This highlights that the choice of model depends on context rather than complexity alone.\nThis does not mean that machine learning has no role in poverty targeting. It means that the “better” model depends on what kind of failure matters most. If the main risk is limited coverage, a complex machine learning  model may help. If the main concern is whether decisions can be justified and trusted, simpler models are safer.\n\n## What Poverty Targeting Teaches Us About Model Choice\nThe case of poverty targeting illustrates a broader lesson for data science practice. Model selection should not be driven solely by benchmark performance. In high-stakes domains, interpretability, auditability, and trust are part of the objective function.\nWhen models allocate resources rather than predict outcomes, accuracy alone is not enough. The best model is not the one with the highest score on a validation set, but the one that works within real institutional constraints.\n\nWhen accuracy is not the objective function, complex models lose their advantage.\n\n## References"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.21","theme":["cosmo","brand"],"title-block-banner":true,"title":"Why Simple Models Are Sometimes Better","subtitle":"What poverty targeting in public policy reveals about the limits of complex machine learning models","author":"Yanxin Liang","date":"2026-01-18","bibliography":["../../references.bib"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}